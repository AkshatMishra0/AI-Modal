# Optimized Configuration for Sentiment Analysis AI Model
# This configuration includes performance optimizations

# Data paths
data:
  raw_data_path: "data/raw/reviews.csv"
  processed_data_path: "data/processed/"
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  random_seed: 42
  # Memory optimization
  batch_size: 1000  # Process data in batches
  use_chunks: true  # Use chunking for large datasets

# Model parameters (optimized)
model:
  type: "logistic_regression"  # Faster than SVM, more accurate than Naive Bayes
  max_features: 10000  # Increased for better performance
  ngram_range: [1, 2]  # Use unigrams and bigrams
  min_df: 2
  max_df: 0.95
  use_idf: true
  sublinear_tf: true  # Better for large documents
  # Classifier-specific optimizations
  solver: "saga"  # Fast solver for large datasets
  C: 1.0
  max_iter: 1000
  n_jobs: -1  # Use all CPU cores

# Training parameters (optimized)
training:
  save_model_path: "models/sentiment_model.pkl"
  save_vectorizer_path: "models/vectorizer.pkl"
  save_metrics_path: "models/metrics.json"
  # Cross-validation
  use_cv: true
  cv_folds: 5
  # Early stopping (for iterative models)
  early_stopping: true
  validation_fraction: 0.1
  n_iter_no_change: 10

# Preprocessing (optimized)
preprocessing:
  lowercase: true
  remove_stopwords: true
  remove_punctuation: true
  remove_numbers: false
  lemmatize: true
  # Performance optimizations
  use_cache: true  # Cache preprocessed texts
  use_parallel: true  # Use parallel processing for large batches
  max_workers: null  # null = auto-detect, or set specific number
  batch_threshold: 100  # Use parallel processing for batches > this size

# Performance settings
performance:
  # Memory optimization
  use_sparse_matrix: true
  dtype: "float32"  # Use float32 instead of float64 to save memory
  # Caching
  cache_size: 1000  # Maximum cached items
  # Logging
  verbose: 1  # 0=silent, 1=progress, 2=detailed

# Logging
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  save_to_file: true
  log_file: "logs/training.log"
